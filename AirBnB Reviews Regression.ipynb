{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asl4a\\AppData\\Roaming\\Python\\Python310\\site-packages\\cupy\\_environment.py:487: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  CuPy may not function correctly because multiple CuPy packages are installed\n",
      "  in your environment:\n",
      "\n",
      "    cupy-cuda11x, cupy-cuda12x\n",
      "\n",
      "  Follow these steps to resolve this issue:\n",
      "\n",
      "    1. For all packages listed above, run the following command to remove all\n",
      "       existing CuPy installations:\n",
      "\n",
      "         $ pip uninstall <package_name>\n",
      "\n",
      "      If you previously installed CuPy via conda, also run the following:\n",
      "\n",
      "         $ conda uninstall cupy\n",
      "\n",
      "    2. Install the appropriate CuPy package.\n",
      "       Refer to the Installation Guide for detailed instructions.\n",
      "\n",
      "         https://docs.cupy.dev/en/stable/install.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  warnings.warn(f'''\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import gzip\n",
    "import shutil\n",
    "import pathlib\n",
    "import os\n",
    "import sqlalchemy\n",
    "import sqlite3\n",
    "import spacy\n",
    "import re\n",
    "import spacy_cleaner\n",
    "from spacy_cleaner import processing, Cleaner\n",
    "import re\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntProgress, HTML, VBox\n",
    "from IPython.display import display\n",
    "import time\n",
    "import timeit\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "%matplotlib inline\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "\n",
    "#spacy.prefer_gpu()\n",
    "spacy.require_gpu(gpu_id=0)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# This loads a larger and more robust model. Use with caution though because it takes considerably longer to run\n",
    "#nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "#nlp = spacy.load('/path/to/en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def print_files_in_directory(directory_path):\n",
    "    with os.scandir(directory_path) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                print(entry.name)\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    sentiment_scores = sid_obj.polarity_scores(text)\n",
    "    return sentiment_scores\n",
    "\n",
    "def clean_text(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    cleaned_tokens = [token.lemma_.lower().strip() for token in doc if not token.is_punct and not token.is_space]\n",
    "    cleaned_tokens = [token for token in cleaned_tokens if not nlp.vocab[token].is_stop]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    cleaner = Cleaner(\n",
    "        nlp,\n",
    "        processing.remove_number_token\n",
    "    )\n",
    "    return cleaner.clean(text)\n",
    "\n",
    "def remove_numbers_regex(text):\n",
    "    # Pattern to remove numbers from text data\n",
    "    pattern = r\"\\d+\"\n",
    "\n",
    "    return re.sub(pattern,\"\",text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(r\"C:/Users/asl4a/AirBnB_Data.db\")\n",
    "cursor = conn.cursor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "    r.id,\n",
    "    r.temp_index,\n",
    "    r.comments,\n",
    "    l.id,\n",
    "    l.review_scores_rating,\n",
    "    l.review_scores_accuracy,\n",
    "    l.review_scores_cleanliness,\n",
    "    l.review_scores_checkin,\n",
    "    l.review_scores_communication,\n",
    "    l.review_scores_location,\n",
    "    l.review_scores_value\n",
    "FROM\n",
    "    listings l\n",
    "JOIN reviews r ON l.id = r.id;\"\"\"\n",
    "\n",
    "df_revs = pd.read_sql(sql,con=conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 843 entries, 0 to 842\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   id                           843 non-null    int64  \n",
      " 1   temp_index                   843 non-null    int64  \n",
      " 2   comments                     843 non-null    object \n",
      " 3   id                           843 non-null    int64  \n",
      " 4   review_scores_rating         745 non-null    float64\n",
      " 5   review_scores_accuracy       739 non-null    float64\n",
      " 6   review_scores_cleanliness    739 non-null    float64\n",
      " 7   review_scores_checkin        739 non-null    float64\n",
      " 8   review_scores_communication  739 non-null    float64\n",
      " 9   review_scores_location       739 non-null    float64\n",
      " 10  review_scores_value          739 non-null    float64\n",
      "dtypes: float64(7), int64(3), object(1)\n",
      "memory usage: 72.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_revs.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_revs['cleaned_text'] = df_revs['comments'].apply(remove_numbers_regex)\n",
    "df_revs['comments'] = df_revs['comments'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Processing text data...:   0%|          | 0/843 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6c71ea8173049f199bf068e60a417e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beg_slice = 0\n",
    "\n",
    "\n",
    "total_iterations = len(df_revs['cleaned_text'][beg_slice:])\n",
    "progress_bar = tqdm(total=total_iterations,desc='Processing text data...')\n",
    "\n",
    "cleaned_text_list = []\n",
    "\n",
    "for i in df_revs['cleaned_text'][beg_slice:]:\n",
    "    cleaned_text_list.append(clean_text(i))\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_revs['processed_text'] = pd.Series(cleaned_text_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_revs = df_revs.dropna(how='any',axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 739 entries, 0 to 842\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   id                           739 non-null    int64  \n",
      " 1   temp_index                   739 non-null    int64  \n",
      " 2   comments                     739 non-null    object \n",
      " 3   id                           739 non-null    int64  \n",
      " 4   review_scores_rating         739 non-null    float64\n",
      " 5   review_scores_accuracy       739 non-null    float64\n",
      " 6   review_scores_cleanliness    739 non-null    float64\n",
      " 7   review_scores_checkin        739 non-null    float64\n",
      " 8   review_scores_communication  739 non-null    float64\n",
      " 9   review_scores_location       739 non-null    float64\n",
      " 10  review_scores_value          739 non-null    float64\n",
      " 11  cleaned_text                 739 non-null    object \n",
      " 12  processed_text               739 non-null    object \n",
      "dtypes: float64(7), int64(3), object(3)\n",
      "memory usage: 80.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_revs.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_revs['processed_text'],df_revs['review_scores_rating'],test_size=0.2,random_state=42)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "regressor.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test_tfidf)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.19417794675675684"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.00017321, 0.        , 0.00088891, ..., 0.        , 0.        ,\n       0.        ])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.feature_importances_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "features_df = pd.DataFrame({'Feature': feature_names,'Feature_Weights': regressor.feature_importances_})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "          Feature  Feature_Weights\n502      bustling         0.041110\n3345           th         0.039701\n3105         soak         0.035380\n28         accord         0.032165\n3229       street         0.024725\n3202      staying         0.023151\n2020     locality         0.019576\n1841         joes         0.016946\n1585       herald         0.016578\n2404         open         0.016106\n759       connect         0.015721\n201         aptos         0.015428\n2012          liz         0.014729\n404         billy         0.014499\n2095    manhattan         0.014438\n3455       trimet         0.014215\n2322       nisene         0.013711\n778    convenient         0.012956\n2348   noteworthy         0.012741\n3118         solo         0.012602\n3007           sf         0.012424\n1977         life         0.012355\n3100       smooth         0.011246\n1870       kanita         0.011235\n2115        marks         0.010602\n1323       forest         0.010583\n3311         talk         0.010248\n1649        house         0.010191\n650   circulation         0.009748\n1640         host         0.009273",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Feature_Weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>502</th>\n      <td>bustling</td>\n      <td>0.041110</td>\n    </tr>\n    <tr>\n      <th>3345</th>\n      <td>th</td>\n      <td>0.039701</td>\n    </tr>\n    <tr>\n      <th>3105</th>\n      <td>soak</td>\n      <td>0.035380</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>accord</td>\n      <td>0.032165</td>\n    </tr>\n    <tr>\n      <th>3229</th>\n      <td>street</td>\n      <td>0.024725</td>\n    </tr>\n    <tr>\n      <th>3202</th>\n      <td>staying</td>\n      <td>0.023151</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>locality</td>\n      <td>0.019576</td>\n    </tr>\n    <tr>\n      <th>1841</th>\n      <td>joes</td>\n      <td>0.016946</td>\n    </tr>\n    <tr>\n      <th>1585</th>\n      <td>herald</td>\n      <td>0.016578</td>\n    </tr>\n    <tr>\n      <th>2404</th>\n      <td>open</td>\n      <td>0.016106</td>\n    </tr>\n    <tr>\n      <th>759</th>\n      <td>connect</td>\n      <td>0.015721</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>aptos</td>\n      <td>0.015428</td>\n    </tr>\n    <tr>\n      <th>2012</th>\n      <td>liz</td>\n      <td>0.014729</td>\n    </tr>\n    <tr>\n      <th>404</th>\n      <td>billy</td>\n      <td>0.014499</td>\n    </tr>\n    <tr>\n      <th>2095</th>\n      <td>manhattan</td>\n      <td>0.014438</td>\n    </tr>\n    <tr>\n      <th>3455</th>\n      <td>trimet</td>\n      <td>0.014215</td>\n    </tr>\n    <tr>\n      <th>2322</th>\n      <td>nisene</td>\n      <td>0.013711</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>convenient</td>\n      <td>0.012956</td>\n    </tr>\n    <tr>\n      <th>2348</th>\n      <td>noteworthy</td>\n      <td>0.012741</td>\n    </tr>\n    <tr>\n      <th>3118</th>\n      <td>solo</td>\n      <td>0.012602</td>\n    </tr>\n    <tr>\n      <th>3007</th>\n      <td>sf</td>\n      <td>0.012424</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>life</td>\n      <td>0.012355</td>\n    </tr>\n    <tr>\n      <th>3100</th>\n      <td>smooth</td>\n      <td>0.011246</td>\n    </tr>\n    <tr>\n      <th>1870</th>\n      <td>kanita</td>\n      <td>0.011235</td>\n    </tr>\n    <tr>\n      <th>2115</th>\n      <td>marks</td>\n      <td>0.010602</td>\n    </tr>\n    <tr>\n      <th>1323</th>\n      <td>forest</td>\n      <td>0.010583</td>\n    </tr>\n    <tr>\n      <th>3311</th>\n      <td>talk</td>\n      <td>0.010248</td>\n    </tr>\n    <tr>\n      <th>1649</th>\n      <td>house</td>\n      <td>0.010191</td>\n    </tr>\n    <tr>\n      <th>650</th>\n      <td>circulation</td>\n      <td>0.009748</td>\n    </tr>\n    <tr>\n      <th>1640</th>\n      <td>host</td>\n      <td>0.009273</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.sort_values(by='Feature_Weights',ascending=False)[:30]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
